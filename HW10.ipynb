{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPBVGpxlbCZbd8RnBbvGmk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ellie456789/STA365HW/blob/main/HW10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QI6_wUxDj_qE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "tcBkGzvakIXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian Processes :  type of stochastic process where any finite set of random variables has a joint multivariate normal distribution with\n",
        "a mean function m(x) = E[f(x)] and covariance function (E[f(x)]-m(x)) (f(x')-m(x'))\n",
        "stochastic processes : random variables indexed by time or space, which describes a system that evolves randomly over time. And the entire process defines a distribution over possible outcomes.\n"
      ],
      "metadata": {
        "id": "TpugdHzpk3xD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variational inference using the Evidence Lower Bound (ELBO) : Variational Inference is a method used in Bayesian statistics to approximate complex posterior distributions with simpler ones by turning the problem into an optimization task. Instead of sampling from the true posterior, VI introduces a family of candidate distributions and finds the one that is closest to the true posterior by maximizing the Evidence Lower Bound (ELBO). The ELBO is a function that balances how well the model explains the observed data and how close the approximate distribution is to the true posterior. By maximizing the ELBO, we effectively minimize the divergence between the approximation and the actual posterior, allowing for efficient and scalable inference in complex models."
      ],
      "metadata": {
        "id": "D1wNSSBbluAN"
      }
    }
  ]
}